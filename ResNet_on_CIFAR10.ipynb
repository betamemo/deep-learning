{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "Jl1HZOTkrFfm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10"
      ],
      "metadata": {
        "id": "Dc0x82MKrNx7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"GPU is not available\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7xU6lrD2YZd",
        "outputId": "702b3a8a-2365-4545-ac0e-79cc14cfdc48"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = CIFAR10(root='./data',\n",
        "                        train=True,\n",
        "                        download=True,\n",
        "                        transform=torchvision.transforms.ToTensor())\n",
        "dataset_test = CIFAR10(root='./data',\n",
        "                       train=False,\n",
        "                       download=True,\n",
        "                       transform=torchvision.transforms.ToTensor())"
      ],
      "metadata": {
        "id": "6HuXA2EPrTO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d804c2-774b-4232-fa29-702f78883ba4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "index = 3\n",
        "\n",
        "image = dataset_train[index][0]\n",
        "label = dataset_train[index][1]\n",
        "\n",
        "plt.imshow(image.permute(1, 2, 0))\n",
        "plt.show()\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ZM6ZgdZlbM59",
        "outputId": "4fb0c763-a054-4929-c993-ef9feed0ee29"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "29SbgTsTYY2L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining the ResNet20 Model\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.linear = nn.Linear(256, num_classes)  # Adjusted to 256\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def ResNet20():\n",
        "    return ResNet(BasicBlock, [3, 3, 3])"
      ],
      "metadata": {
        "id": "Jg9tk_CRm4Bp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = ResNet20().to(device)"
      ],
      "metadata": {
        "id": "qJMna_ThW7RR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_number = 100\n",
        "\n",
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "val_loss_history = []\n",
        "val_accuracy_history = []\n",
        "\n",
        "def train(epoch):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_dataloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    train_loss_history.append(train_loss / len(train_dataloader))\n",
        "    train_accuracy_history.append(100. * correct / total)\n",
        "    print(f'Epoch {epoch} | Train Loss: {train_loss/len(train_dataloader):.3f} | Train Acc: {100.*correct/total:.3f}%')\n",
        "\n",
        "def test(epoch):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_dataloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    val_loss_history.append(test_loss / len(test_dataloader))\n",
        "    val_accuracy_history.append(100. * correct / total)\n",
        "    print(f'Epoch {epoch} | Test Loss: {test_loss/len(test_dataloader):.3f} | Test Acc: {100.*correct/total:.3f}%')\n"
      ],
      "metadata": {
        "id": "zl3I-U4qyFen",
        "collapsed": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss function, and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Training and testing the model\n",
        "epochs = epoch_number\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "\n",
        "# Plotting the loss and accuracy history\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss_history, label='Train Loss')\n",
        "plt.plot(val_loss_history, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss History')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy_history, label='Train Accuracy')\n",
        "plt.plot(val_accuracy_history, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy History')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWg3fxiInZHN",
        "outputId": "aec285af-5cc0-42da-fbe6-bd32c4a44846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Train Loss: 1.894 | Train Acc: 31.350%\n",
            "Epoch 0 | Test Loss: 1.612 | Test Acc: 41.860%\n",
            "Epoch 1 | Train Loss: 1.358 | Train Acc: 50.726%\n",
            "Epoch 1 | Test Loss: 1.360 | Test Acc: 51.830%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_loss_history)\n",
        "plt.plot(val_loss_history)"
      ],
      "metadata": {
        "id": "mr4ZzAHGxC5z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "a9cfc6c8-9fb0-421e-db2d-9c2542fd8f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loss_history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4701462e2097>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loss_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_accuracy_history)\n",
        "plt.plot(val_accuracy_history)"
      ],
      "metadata": {
        "id": "8i6bvnNstKwS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "df020ffb-3fea-43a2-b931-8bf1345e0766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_accuracy_history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a672284c2d15>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracy_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_accuracy_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  57.76"
      ],
      "metadata": {
        "id": "ptR024Vht92X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.linear = nn.Linear(256, num_classes)  # Adjusted to 256\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        # print(out.shape)  # Debugging shape\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def ResNet20():\n",
        "    return ResNet(BasicBlock, [3, 3, 3])\n",
        "\n",
        "# Prepare CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = ResNet20().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "epoch_number = 100\n",
        "\n",
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "val_loss_history = []\n",
        "val_accuracy_history = []\n",
        "\n",
        "def train(epoch):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    train_loss_history.append(train_loss / len(trainloader))\n",
        "    train_accuracy_history.append(100. * correct / total)\n",
        "    print(f'Epoch {epoch} | Train Loss: {train_loss/len(trainloader):.3f} | Train Acc: {100.*correct/total:.3f}%')\n",
        "\n",
        "def test(epoch):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    val_loss_history.append(test_loss / len(testloader))\n",
        "    val_accuracy_history.append(100. * correct / total)\n",
        "    print(f'Epoch {epoch} | Test Loss: {test_loss/len(testloader):.3f} | Test Acc: {100.*correct/total:.3f}%')\n",
        "\n",
        "# Training and testing the model\n",
        "epochs = epoch_number\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "\n",
        "# Plotting the loss and accuracy history\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss_history, label='Train Loss')\n",
        "plt.plot(val_loss_history, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss History')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy_history, label='Train Accuracy')\n",
        "plt.plot(val_accuracy_history, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy History')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TFBCrdmCsDd0",
        "outputId": "b343e730-8a4d-4ab0-b328-57d21e71aead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 0 | Train Loss: 1.868 | Train Acc: 32.198%\n",
            "Epoch 0 | Test Loss: 1.637 | Test Acc: 39.860%\n",
            "Epoch 1 | Train Loss: 1.403 | Train Acc: 48.810%\n",
            "Epoch 1 | Test Loss: 1.286 | Test Acc: 54.690%\n",
            "Epoch 2 | Train Loss: 1.063 | Train Acc: 62.258%\n",
            "Epoch 2 | Test Loss: 1.049 | Test Acc: 63.170%\n",
            "Epoch 3 | Train Loss: 0.863 | Train Acc: 69.698%\n",
            "Epoch 3 | Test Loss: 1.054 | Test Acc: 64.270%\n",
            "Epoch 4 | Train Loss: 0.757 | Train Acc: 73.606%\n",
            "Epoch 4 | Test Loss: 0.934 | Test Acc: 68.670%\n",
            "Epoch 5 | Train Loss: 0.699 | Train Acc: 75.856%\n",
            "Epoch 5 | Test Loss: 0.746 | Test Acc: 73.690%\n",
            "Epoch 6 | Train Loss: 0.660 | Train Acc: 77.120%\n",
            "Epoch 6 | Test Loss: 0.837 | Test Acc: 71.630%\n",
            "Epoch 7 | Train Loss: 0.628 | Train Acc: 78.364%\n",
            "Epoch 7 | Test Loss: 0.813 | Test Acc: 73.200%\n",
            "Epoch 8 | Train Loss: 0.603 | Train Acc: 79.238%\n",
            "Epoch 8 | Test Loss: 0.850 | Test Acc: 72.090%\n",
            "Epoch 9 | Train Loss: 0.586 | Train Acc: 79.694%\n",
            "Epoch 9 | Test Loss: 0.629 | Test Acc: 78.510%\n",
            "Epoch 10 | Train Loss: 0.574 | Train Acc: 80.166%\n",
            "Epoch 10 | Test Loss: 0.783 | Test Acc: 74.460%\n",
            "Epoch 11 | Train Loss: 0.561 | Train Acc: 80.562%\n",
            "Epoch 11 | Test Loss: 1.176 | Test Acc: 64.020%\n",
            "Epoch 12 | Train Loss: 0.554 | Train Acc: 80.880%\n",
            "Epoch 12 | Test Loss: 0.672 | Test Acc: 77.530%\n",
            "Epoch 13 | Train Loss: 0.543 | Train Acc: 81.234%\n",
            "Epoch 13 | Test Loss: 0.720 | Test Acc: 75.740%\n",
            "Epoch 14 | Train Loss: 0.534 | Train Acc: 81.698%\n",
            "Epoch 14 | Test Loss: 1.394 | Test Acc: 63.600%\n",
            "Epoch 15 | Train Loss: 0.526 | Train Acc: 81.842%\n",
            "Epoch 15 | Test Loss: 0.676 | Test Acc: 77.880%\n",
            "Epoch 16 | Train Loss: 0.519 | Train Acc: 82.256%\n",
            "Epoch 16 | Test Loss: 0.893 | Test Acc: 71.400%\n",
            "Epoch 17 | Train Loss: 0.514 | Train Acc: 82.322%\n",
            "Epoch 17 | Test Loss: 0.615 | Test Acc: 79.670%\n",
            "Epoch 18 | Train Loss: 0.514 | Train Acc: 82.342%\n",
            "Epoch 18 | Test Loss: 0.727 | Test Acc: 75.150%\n",
            "Epoch 19 | Train Loss: 0.505 | Train Acc: 82.652%\n",
            "Epoch 19 | Test Loss: 0.705 | Test Acc: 76.620%\n",
            "Epoch 20 | Train Loss: 0.507 | Train Acc: 82.562%\n",
            "Epoch 20 | Test Loss: 0.704 | Test Acc: 76.220%\n",
            "Epoch 21 | Train Loss: 0.500 | Train Acc: 82.870%\n",
            "Epoch 21 | Test Loss: 0.675 | Test Acc: 77.450%\n",
            "Epoch 22 | Train Loss: 0.499 | Train Acc: 82.872%\n",
            "Epoch 22 | Test Loss: 0.779 | Test Acc: 74.940%\n",
            "Epoch 23 | Train Loss: 0.498 | Train Acc: 83.116%\n",
            "Epoch 23 | Test Loss: 0.604 | Test Acc: 79.480%\n",
            "Epoch 24 | Train Loss: 0.487 | Train Acc: 83.364%\n",
            "Epoch 24 | Test Loss: 0.657 | Test Acc: 77.410%\n",
            "Epoch 25 | Train Loss: 0.484 | Train Acc: 83.246%\n",
            "Epoch 25 | Test Loss: 0.718 | Test Acc: 76.320%\n",
            "Epoch 26 | Train Loss: 0.480 | Train Acc: 83.494%\n",
            "Epoch 26 | Test Loss: 0.629 | Test Acc: 78.930%\n",
            "Epoch 27 | Train Loss: 0.476 | Train Acc: 83.508%\n",
            "Epoch 27 | Test Loss: 0.706 | Test Acc: 76.850%\n",
            "Epoch 28 | Train Loss: 0.485 | Train Acc: 83.402%\n",
            "Epoch 28 | Test Loss: 0.666 | Test Acc: 78.240%\n",
            "Epoch 29 | Train Loss: 0.475 | Train Acc: 83.766%\n",
            "Epoch 29 | Test Loss: 0.893 | Test Acc: 70.960%\n",
            "Epoch 30 | Train Loss: 0.474 | Train Acc: 83.698%\n",
            "Epoch 30 | Test Loss: 0.549 | Test Acc: 81.460%\n",
            "Epoch 31 | Train Loss: 0.480 | Train Acc: 83.394%\n",
            "Epoch 31 | Test Loss: 0.651 | Test Acc: 78.060%\n",
            "Epoch 32 | Train Loss: 0.471 | Train Acc: 83.880%\n",
            "Epoch 32 | Test Loss: 0.606 | Test Acc: 79.790%\n",
            "Epoch 33 | Train Loss: 0.467 | Train Acc: 83.976%\n",
            "Epoch 33 | Test Loss: 0.640 | Test Acc: 77.630%\n",
            "Epoch 34 | Train Loss: 0.462 | Train Acc: 83.972%\n",
            "Epoch 34 | Test Loss: 0.669 | Test Acc: 77.360%\n",
            "Epoch 35 | Train Loss: 0.468 | Train Acc: 83.810%\n",
            "Epoch 35 | Test Loss: 0.800 | Test Acc: 74.110%\n",
            "Epoch 36 | Train Loss: 0.464 | Train Acc: 84.010%\n",
            "Epoch 36 | Test Loss: 0.673 | Test Acc: 77.180%\n",
            "Epoch 37 | Train Loss: 0.460 | Train Acc: 84.236%\n",
            "Epoch 37 | Test Loss: 0.720 | Test Acc: 76.610%\n",
            "Epoch 38 | Train Loss: 0.463 | Train Acc: 84.130%\n",
            "Epoch 38 | Test Loss: 0.724 | Test Acc: 75.870%\n",
            "Epoch 39 | Train Loss: 0.464 | Train Acc: 84.106%\n",
            "Epoch 39 | Test Loss: 0.646 | Test Acc: 78.800%\n",
            "Epoch 40 | Train Loss: 0.468 | Train Acc: 83.968%\n",
            "Epoch 40 | Test Loss: 0.643 | Test Acc: 78.700%\n",
            "Epoch 41 | Train Loss: 0.457 | Train Acc: 84.298%\n",
            "Epoch 41 | Test Loss: 0.638 | Test Acc: 78.700%\n",
            "Epoch 42 | Train Loss: 0.459 | Train Acc: 84.332%\n",
            "Epoch 42 | Test Loss: 0.604 | Test Acc: 79.740%\n",
            "Epoch 43 | Train Loss: 0.457 | Train Acc: 84.260%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-3aac98ea751f>\u001b[0m in \u001b[0;36m<cell line: 140>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;31m# Plotting the loss and accuracy history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-3aac98ea751f>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}